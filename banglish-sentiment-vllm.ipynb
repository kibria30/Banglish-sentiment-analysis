{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":108644,"databundleVersionId":13168647,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":282751,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":239470,"modelId":222398},{"sourceId":282742,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":239467,"modelId":222398}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os, math, numpy as np\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T04:50:11.885353Z","iopub.execute_input":"2025-07-26T04:50:11.885534Z","iopub.status.idle":"2025-07-26T04:50:11.892659Z","shell.execute_reply.started":"2025-07-26T04:50:11.885517Z","shell.execute_reply":"2025-07-26T04:50:11.892093Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# %%time\n# !pip uninstall -y torch\n# !pip install -U --no-index --find-links=/kaggle/input/vllm-whl -U vllm\n# !pip install -U --upgrade /kaggle/input/vllm-t4-fix/grpcio-1.62.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n# !pip install -U --upgrade /kaggle/input/vllm-t4-fix/ray-2.11.0-cp310-cp310-manylinux2014_x86_64.whl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T04:51:49.037584Z","iopub.execute_input":"2025-07-26T04:51:49.038282Z","iopub.status.idle":"2025-07-26T04:51:49.041802Z","shell.execute_reply.started":"2025-07-26T04:51:49.038248Z","shell.execute_reply":"2025-07-26T04:51:49.041056Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!pip install vllm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T04:51:56.763659Z","iopub.execute_input":"2025-07-26T04:51:56.763908Z","iopub.status.idle":"2025-07-26T04:55:13.551927Z","shell.execute_reply.started":"2025-07-26T04:51:56.763888Z","shell.execute_reply":"2025-07-26T04:55:13.551174Z"}},"outputs":[{"name":"stdout","text":"Collecting vllm\n  Downloading vllm-0.10.0-cp38-abi3-manylinux1_x86_64.whl.metadata (14 kB)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from vllm) (2024.11.6)\nRequirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from vllm) (5.5.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from vllm) (7.0.0)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from vllm) (0.2.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from vllm) (1.26.4)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.32.4)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from vllm) (4.67.1)\nCollecting blake3 (from vllm)\n  Downloading blake3-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from vllm) (9.0.0)\nCollecting transformers>=4.53.2 (from vllm)\n  Downloading transformers-4.54.0-py3-none-any.whl.metadata (41 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: huggingface-hub>=0.33.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub[hf_xet]>=0.33.0->vllm) (0.33.1)\nRequirement already satisfied: tokenizers>=0.21.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.2)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from vllm) (3.20.3)\nRequirement already satisfied: fastapi>=0.115.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.115.13)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from vllm) (3.12.13)\nCollecting openai<=1.90.0,>=1.87.0 (from vllm)\n  Downloading openai-1.90.0-py3-none-any.whl.metadata (26 kB)\nRequirement already satisfied: pydantic>=2.10 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.11.7)\nRequirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.22.1)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from vllm) (11.2.1)\nCollecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm)\n  Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.9.0)\nCollecting lm-format-enforcer<0.11,>=0.10.11 (from vllm)\n  Downloading lm_format_enforcer-0.10.11-py3-none-any.whl.metadata (17 kB)\nCollecting llguidance<0.8.0,>=0.7.11 (from vllm)\n  Downloading llguidance-0.7.30-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\nCollecting outlines_core==0.2.10 (from vllm)\n  Downloading outlines_core-0.2.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\nCollecting diskcache==5.6.3 (from vllm)\n  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\nCollecting lark==1.2.2 (from vllm)\n  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\nCollecting xgrammar==0.1.21 (from vllm)\n  Downloading xgrammar-0.1.21-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\nRequirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.14.0)\nRequirement already satisfied: filelock>=3.16.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (3.18.0)\nCollecting partial-json-parser (from vllm)\n  Downloading partial_json_parser-0.2.1.1.post6-py3-none-any.whl.metadata (6.1 kB)\nCollecting pyzmq>=25.0.0 (from vllm)\n  Downloading pyzmq-27.0.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.0 kB)\nCollecting msgspec (from vllm)\n  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\nCollecting gguf>=0.13.0 (from vllm)\n  Downloading gguf-0.17.1-py3-none-any.whl.metadata (4.3 kB)\nCollecting mistral_common>=1.8.2 (from mistral_common[audio,image]>=1.8.2->vllm)\n  Downloading mistral_common-1.8.3-py3-none-any.whl.metadata (3.8 kB)\nRequirement already satisfied: opencv-python-headless>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.11.0.86)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from vllm) (6.0.2)\nRequirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from vllm) (0.8.1)\nCollecting compressed-tensors==0.10.2 (from vllm)\n  Downloading compressed_tensors-0.10.2-py3-none-any.whl.metadata (7.0 kB)\nCollecting depyf==0.19.0 (from vllm)\n  Downloading depyf-0.19.0-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from vllm) (3.1.1)\nCollecting watchfiles (from vllm)\n  Downloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\nRequirement already satisfied: python-json-logger in /usr/local/lib/python3.11/dist-packages (from vllm) (3.3.0)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from vllm) (1.15.3)\nRequirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from vllm) (1.11.1.4)\nCollecting pybase64 (from vllm)\n  Downloading pybase64-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\nCollecting cbor2 (from vllm)\n  Downloading cbor2-5.6.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\nCollecting numba==0.61.2 (from vllm)\n  Downloading numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\nRequirement already satisfied: ray!=2.44.*,>=2.43.0 in /usr/local/lib/python3.11/dist-packages (from ray[cgraph]!=2.44.*,>=2.43.0->vllm) (2.47.1)\nCollecting torch==2.7.1 (from vllm)\n  Downloading torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\nCollecting torchaudio==2.7.1 (from vllm)\n  Downloading torchaudio-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\nCollecting torchvision==0.22.1 (from vllm)\n  Downloading torchvision-0.22.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\nCollecting xformers==0.0.31 (from vllm)\n  Downloading xformers-0.0.31-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\nCollecting astor (from depyf==0.19.0->vllm)\n  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from depyf==0.19.0->vllm) (0.3.8)\nCollecting llvmlite<0.45,>=0.44.0dev0 (from numba==0.61.2->vllm)\n  Downloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\nCollecting sympy>=1.13.3 (from torch==2.7.1->vllm)\n  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch==2.7.1->vllm)\n  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.6.77 (from torch==2.7.1->vllm)\n  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.6.80 (from torch==2.7.1->vllm)\n  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.5.1.17 (from torch==2.7.1->vllm)\n  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.6.4.1 (from torch==2.7.1->vllm)\n  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.3.0.4 (from torch==2.7.1->vllm)\n  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.7.77 (from torch==2.7.1->vllm)\n  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.7.1.2 (from torch==2.7.1->vllm)\n  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.5.4.2 (from torch==2.7.1->vllm)\n  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparselt-cu12==0.6.3 (from torch==2.7.1->vllm)\n  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting nvidia-nccl-cu12==2.26.2 (from torch==2.7.1->vllm)\n  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\nCollecting nvidia-nvtx-cu12==12.6.77 (from torch==2.7.1->vllm)\n  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nvjitlink-cu12==12.6.85 (from torch==2.7.1->vllm)\n  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufile-cu12==1.11.1.6 (from torch==2.7.1->vllm)\n  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting triton==3.3.1 (from torch==2.7.1->vllm)\n  Downloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.1->torch==2.7.1->vllm) (75.2.0)\nRequirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (0.46.2)\nCollecting fastapi-cli>=0.0.5 (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n  Downloading fastapi_cli-0.0.8-py3-none-any.whl.metadata (6.3 kB)\nRequirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.28.1)\nRequirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.0.20)\nRequirement already satisfied: email-validator>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (2.2.0)\nRequirement already satisfied: uvicorn>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.34.3)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.0->huggingface-hub[hf_xet]>=0.33.0->vllm) (25.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.0->huggingface-hub[hf_xet]>=0.33.0->vllm) (1.1.5)\nCollecting interegular>=0.3.2 (from lm-format-enforcer<0.11,>=0.10.11->vllm)\n  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: jsonschema>=4.21.1 in /usr/local/lib/python3.11/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (4.24.0)\nCollecting pydantic-extra-types>=2.10.5 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm)\n  Downloading pydantic_extra_types-2.10.5-py3-none-any.whl.metadata (3.9 kB)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->vllm) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->vllm) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->vllm) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->vllm) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->vllm) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->vllm) (2.4.1)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<=1.90.0,>=1.87.0->vllm) (4.9.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<=1.90.0,>=1.87.0->vllm) (1.9.0)\nRequirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<=1.90.0,>=1.87.0->vllm) (0.10.0)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<=1.90.0,>=1.87.0->vllm) (1.3.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10->vllm) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10->vllm) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10->vllm) (0.4.1)\nRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (8.2.1)\nRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (1.1.1)\nRequirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.11/dist-packages (from ray[cgraph]!=2.44.*,>=2.43.0->vllm) (13.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (2025.6.15)\nINFO: pip is looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.\nCollecting transformers>=4.53.2 (from vllm)\n  Downloading transformers-4.53.3-py3-none-any.whl.metadata (40 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.53.2->vllm) (0.5.3)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.20.1)\nRequirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm) (2.7.0)\nRequirement already satisfied: typer>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.16.0)\nCollecting rich-toolkit>=0.14.8 (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n  Downloading rich_toolkit-0.14.8-py3-none-any.whl.metadata (999 bytes)\nCollecting fastapi-cloud-cli>=0.1.1 (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n  Downloading fastapi_cloud_cli-0.1.4-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (0.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.7.1->vllm) (3.0.2)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (2025.4.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.25.1)\nCollecting pycountry>=23 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm)\n  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch==2.7.1->vllm) (1.3.0)\nCollecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\nCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\nCollecting uvloop>=0.15.1 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\nRequirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (15.0.1)\nRequirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (0.8.3)\nRequirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.13.1)\nRequirement already satisfied: soxr>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.5.0.post1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->vllm) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->vllm) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->vllm) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->vllm) (2024.2.0)\nCollecting rignore>=0.5.1 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n  Downloading rignore-0.6.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\nRequirement already satisfied: sentry-sdk>=2.20.0 in /usr/local/lib/python3.11/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.31.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->vllm) (2024.2.0)\nRequirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.11/dist-packages (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (14.0.0)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (1.17.1)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.15.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.5.4)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (2.22)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.19.2)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.1.2)\nDownloading vllm-0.10.0-cp38-abi3-manylinux1_x86_64.whl (386.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading compressed_tensors-0.10.2-py3-none-any.whl (169 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.0/169.0 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading depyf-0.19.0-py3-none-any.whl (39 kB)\nDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading lark-1.2.2-py3-none-any.whl (111 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading outlines_core-0.2.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl (821.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.2/821.2 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchaudio-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl (3.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading torchvision-0.22.1-cp311-cp311-manylinux_2_28_x86_64.whl (7.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading xformers-0.0.31-cp39-abi3-manylinux_2_28_x86_64.whl (117.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.1/117.1 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading xgrammar-0.1.21-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m104.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gguf-0.17.1-py3-none-any.whl (96 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading llguidance-0.7.30-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.0/15.0 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading lm_format_enforcer-0.10.11-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading mistral_common-1.8.3-py3-none-any.whl (6.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading openai-1.90.0-py3-none-any.whl (734 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m734.6/734.6 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl (19 kB)\nDownloading pyzmq-27.0.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (856 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.6/856.6 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading transformers-4.53.3-py3-none-any.whl (10.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading blake3-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (385 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.5/385.5 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cbor2-5.6.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (249 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.2/249.2 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading partial_json_parser-0.2.1.1.post6-py3-none-any.whl (10 kB)\nDownloading pybase64-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (71 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.2/71.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fastapi_cli-0.0.8-py3-none-any.whl (10 kB)\nDownloading interegular-0.3.3-py37-none-any.whl (23 kB)\nDownloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pydantic_extra_types-2.10.5-py3-none-any.whl (38 kB)\nDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\nDownloading fastapi_cloud_cli-0.1.4-py3-none-any.whl (18 kB)\nDownloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\nDownloading rich_toolkit-0.14.8-py3-none-any.whl (24 kB)\nDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading rignore-0.6.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (950 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.6/950.6 kB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, blake3, uvloop, triton, sympy, rignore, pyzmq, python-dotenv, pycountry, pybase64, partial-json-parser, outlines_core, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, msgspec, llvmlite, llguidance, lark, interegular, httptools, diskcache, cbor2, astor, watchfiles, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, depyf, rich-toolkit, pydantic-extra-types, prometheus-fastapi-instrumentator, openai, nvidia-cusolver-cu12, lm-format-enforcer, torch, fastapi-cloud-cli, fastapi-cli, torchaudio, mistral_common, transformers, xgrammar, xformers, torchvision, numba, gguf, compressed-tensors, vllm\n  Attempting uninstall: nvidia-cusparselt-cu12\n    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n  Attempting uninstall: triton\n    Found existing installation: triton 3.2.0\n    Uninstalling triton-3.2.0:\n      Successfully uninstalled triton-3.2.0\n  Attempting uninstall: sympy\n    Found existing installation: sympy 1.13.1\n    Uninstalling sympy-1.13.1:\n      Successfully uninstalled sympy-1.13.1\n  Attempting uninstall: pyzmq\n    Found existing installation: pyzmq 24.0.1\n    Uninstalling pyzmq-24.0.1:\n      Successfully uninstalled pyzmq-24.0.1\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.4.127\n    Uninstalling nvidia-nvtx-cu12-12.4.127:\n      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.21.5\n    Uninstalling nvidia-nccl-cu12-2.21.5:\n      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: llvmlite\n    Found existing installation: llvmlite 0.43.0\n    Uninstalling llvmlite-0.43.0:\n      Successfully uninstalled llvmlite-0.43.0\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: openai\n    Found existing installation: openai 1.91.0\n    Uninstalling openai-1.91.0:\n      Successfully uninstalled openai-1.91.0\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n  Attempting uninstall: torchaudio\n    Found existing installation: torchaudio 2.6.0+cu124\n    Uninstalling torchaudio-2.6.0+cu124:\n      Successfully uninstalled torchaudio-2.6.0+cu124\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.52.4\n    Uninstalling transformers-4.52.4:\n      Successfully uninstalled transformers-4.52.4\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.21.0+cu124\n    Uninstalling torchvision-0.21.0+cu124:\n      Successfully uninstalled torchvision-0.21.0+cu124\n  Attempting uninstall: numba\n    Found existing installation: numba 0.60.0\n    Uninstalling numba-0.60.0:\n      Successfully uninstalled numba-0.60.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndask-cuda 25.2.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\ncuml-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\ncudf-cu12 25.2.2 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\ndistributed-ucxx-cu12 0.42.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\nydata-profiling 4.16.1 requires numba<=0.61,>=0.56.0, but you have numba 0.61.2 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.4 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.1 which is incompatible.\nfastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.1 which is incompatible.\njupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed astor-0.8.1 blake3-1.0.5 cbor2-5.6.5 compressed-tensors-0.10.2 depyf-0.19.0 diskcache-5.6.3 fastapi-cli-0.0.8 fastapi-cloud-cli-0.1.4 gguf-0.17.1 httptools-0.6.4 interegular-0.3.3 lark-1.2.2 llguidance-0.7.30 llvmlite-0.44.0 lm-format-enforcer-0.10.11 mistral_common-1.8.3 msgspec-0.19.0 numba-0.61.2 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 openai-1.90.0 outlines_core-0.2.10 partial-json-parser-0.2.1.1.post6 prometheus-fastapi-instrumentator-7.1.0 pybase64-1.4.1 pycountry-24.6.1 pydantic-extra-types-2.10.5 python-dotenv-1.1.1 pyzmq-27.0.0 rich-toolkit-0.14.8 rignore-0.6.4 sympy-1.14.0 torch-2.7.1 torchaudio-2.7.1 torchvision-0.22.1 transformers-4.53.3 triton-3.3.1 uvloop-0.21.0 vllm-0.10.0 watchfiles-1.1.0 xformers-0.0.31 xgrammar-0.1.21\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# # In DEBUG mode, infer only on 5 problems\n# DEBUG = False\n# # Number of candidate solutions to generate\n# K = 5\n# DEPTH = 4\n# TEMPERATURE = 0.8\n# TOP_P = 0.8\n# BATCH_SIZE = 64\n# # C_K = 5 # no of context for a problem","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import vllm\nimport re\nimport csv\nimport torch\nimport gc\nfrom tqdm import tqdm\nimport pandas as pd\nfrom queue import Queue, Empty\nimport os\nimport re\nimport signal\nimport subprocess\nimport tempfile\nfrom collections import Counter\nfrom contextlib import contextmanager\n\nimport threading\nfrom concurrent.futures import ThreadPoolExecutor, as_completed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T04:55:13.553533Z","iopub.execute_input":"2025-07-26T04:55:13.553792Z","iopub.status.idle":"2025-07-26T04:55:15.723537Z","shell.execute_reply.started":"2025-07-26T04:55:13.553767Z","shell.execute_reply":"2025-07-26T04:55:15.723015Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"llm = vllm.LLM(\n    \"/kaggle/input/gemma-3/transformers/gemma-3-4b-it/1\",\n    tensor_parallel_size=2, \n    gpu_memory_utilization=0.95, \n    trust_remote_code=True,\n    # dtype=\"bfloat16\", \n    enforce_eager=True,\n    max_model_len=4096,\n)\ntokenizer = llm.get_tokenizer()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T04:57:59.660661Z","iopub.execute_input":"2025-07-26T04:57:59.660951Z","iopub.status.idle":"2025-07-26T05:00:51.431917Z","shell.execute_reply.started":"2025-07-26T04:57:59.660930Z","shell.execute_reply":"2025-07-26T05:00:51.430927Z"}},"outputs":[{"name":"stdout","text":"WARNING 07-26 04:57:59 [config.py:3392] Your device 'Tesla T4' (with compute capability 7.5) doesn't support torch.bfloat16. Falling back to torch.float32 for compatibility.\nINFO 07-26 04:57:59 [config.py:3437] Upcasting torch.bfloat16 to torch.float32.\nINFO 07-26 04:57:59 [config.py:1604] Using max model len 4096\nWARNING 07-26 04:57:59 [cuda.py:103] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used\nINFO 07-26 04:57:59 [llm_engine.py:228] Initializing a V0 LLM engine (v0.10.0) with config: model='/kaggle/input/gemma-3/transformers/gemma-3-4b-it/1', speculative_config=None, tokenizer='/kaggle/input/gemma-3/transformers/gemma-3-4b-it/1', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float32, max_seq_len=4096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=None, served_model_name=/kaggle/input/gemma-3/transformers/gemma-3-4b-it/1, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=False, pooler_config=None, compilation_config={\"level\":0,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":false,\"cudagraph_num_of_warmups\":0,\"cudagraph_capture_sizes\":[],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":0,\"local_cache_dir\":null}, use_cached_outputs=False, \n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/models/gemma3/configuration_gemma3.py:242: FutureWarning: The `sliding_window_pattern` attribute is deprecated and will be removed in v4.55.0.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"INFO 07-26 04:58:01 [cuda.py:346] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\nINFO 07-26 04:58:01 [cuda.py:395] Using XFormers backend.\n","output_type":"stream"},{"name":"stderr","text":"2025-07-26 04:58:05.810652: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753505885.831893     189 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753505885.838526     189 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"INFO 07-26 04:58:11 [__init__.py:235] Automatically detected platform cuda.\n\u001b[1;36m(VllmWorkerProcess pid=189)\u001b[0;0m INFO 07-26 04:58:11 [multiproc_worker_utils.py:226] Worker ready; awaiting tasks\n\u001b[1;36m(VllmWorkerProcess pid=189)\u001b[0;0m INFO 07-26 04:58:12 [cuda.py:346] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n\u001b[1;36m(VllmWorkerProcess pid=189)\u001b[0;0m INFO 07-26 04:58:12 [cuda.py:395] Using XFormers backend.\n","output_type":"stream"},{"name":"stderr","text":"[W726 04:58:23.068547064 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n[W726 04:58:23.417654478 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n[W726 04:58:33.075413787 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n","output_type":"stream"},{"name":"stdout","text":"INFO 07-26 04:58:43 [__init__.py:1375] Found nccl from library libnccl.so.2\n\u001b[1;36m(VllmWorkerProcess pid=189)\u001b[0;0m INFO 07-26 04:58:43 [__init__.py:1375] Found nccl from library libnccl.so.2\n\u001b[1;36m(VllmWorkerProcess pid=189)\u001b[0;0m INFO 07-26 04:58:43 [pynccl.py:70] vLLM is using nccl==2.26.2\nINFO 07-26 04:58:43 [pynccl.py:70] vLLM is using nccl==2.26.2\n","output_type":"stream"},{"name":"stderr","text":"[W726 04:58:43.085951724 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n","output_type":"stream"},{"name":"stdout","text":"INFO 07-26 04:58:43 [custom_all_reduce_utils.py:208] generating GPU P2P access cache in /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\nINFO 07-26 04:59:07 [custom_all_reduce_utils.py:246] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\n\u001b[1;36m(VllmWorkerProcess pid=189)\u001b[0;0m INFO 07-26 04:59:07 [custom_all_reduce_utils.py:246] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\n\u001b[1;36m(VllmWorkerProcess pid=189)\u001b[0;0m WARNING 07-26 04:59:07 [custom_all_reduce.py:147] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.\nWARNING 07-26 04:59:07 [custom_all_reduce.py:147] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.\nINFO 07-26 04:59:07 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_a9b9137e'), local_subscribe_addr='ipc:///tmp/951c491d-9067-4ba7-945e-c57436013f5b', remote_subscribe_addr=None, remote_addr_ipv6=False)\nINFO 07-26 04:59:07 [parallel_state.py:1102] rank 0 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n\u001b[1;36m(VllmWorkerProcess pid=189)\u001b[0;0m INFO 07-26 04:59:07 [parallel_state.py:1102] rank 1 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 1, EP rank 1\nINFO 07-26 04:59:07 [model_runner.py:1083] Starting to load model /kaggle/input/gemma-3/transformers/gemma-3-4b-it/1...\n\u001b[1;36m(VllmWorkerProcess pid=189)\u001b[0;0m INFO 07-26 04:59:07 [model_runner.py:1083] Starting to load model /kaggle/input/gemma-3/transformers/gemma-3-4b-it/1...\n\u001b[1;36m(VllmWorkerProcess pid=189)\u001b[0;0m INFO 07-26 04:59:08 [cuda.py:346] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n\u001b[1;36m(VllmWorkerProcess pid=189)\u001b[0;0m INFO 07-26 04:59:08 [cuda.py:395] Using XFormers backend.\nINFO 07-26 04:59:08 [cuda.py:346] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\nINFO 07-26 04:59:08 [cuda.py:395] Using XFormers backend.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[1;36m(VllmWorkerProcess pid=189)\u001b[0;0m /usr/local/lib/python3.11/dist-packages/transformers/models/gemma3/configuration_gemma3.py:242: FutureWarning: The `sliding_window_pattern` attribute is deprecated and will be removed in v4.55.0.\n\u001b[1;36m(VllmWorkerProcess pid=189)\u001b[0;0m   warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6c8bd3d4736488fa01f8df2d5215b1c"}},"metadata":{}},{"name":"stdout","text":"INFO 07-26 04:59:57 [default_loader.py:262] Loading weights took 48.88 seconds\n\u001b[1;36m(VllmWorkerProcess pid=189)\u001b[0;0m INFO 07-26 04:59:57 [default_loader.py:262] Loading weights took 49.04 seconds\n\u001b[1;36m(VllmWorkerProcess pid=189)\u001b[0;0m INFO 07-26 04:59:58 [model_runner.py:1115] Model loading took 9.1552 GiB and 49.309196 seconds\nINFO 07-26 04:59:58 [model_runner.py:1115] Model loading took 9.1552 GiB and 49.080298 seconds\n","output_type":"stream"},{"name":"stderr","text":"\u001b[1;36m(VllmWorkerProcess pid=189)\u001b[0;0m Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\nUsing a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1;36m(VllmWorkerProcess pid=189)\u001b[0;0m WARNING 07-26 05:00:09 [logger.py:71] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 256) is too short to hold the multi-modal embeddings in the worst case (261 tokens in total, out of which {'image': 256} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.\nWARNING 07-26 05:00:10 [logger.py:71] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 256) is too short to hold the multi-modal embeddings in the worst case (261 tokens in total, out of which {'image': 256} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.\n\u001b[1;36m(VllmWorkerProcess pid=189)\u001b[0;0m INFO 07-26 05:00:46 [worker.py:295] Memory profiling takes 47.94 seconds\n\u001b[1;36m(VllmWorkerProcess pid=189)\u001b[0;0m INFO 07-26 05:00:46 [worker.py:295] the current vLLM instance can use total_gpu_memory (14.74GiB) x gpu_memory_utilization (0.95) = 14.00GiB\n\u001b[1;36m(VllmWorkerProcess pid=189)\u001b[0;0m INFO 07-26 05:00:46 [worker.py:295] model weights take 9.16GiB; non_torch_memory takes 0.11GiB; PyTorch activation peak memory takes 2.95GiB; the rest of the memory reserved for KV Cache is 1.79GiB.\nINFO 07-26 05:00:46 [worker.py:295] Memory profiling takes 47.98 seconds\nINFO 07-26 05:00:46 [worker.py:295] the current vLLM instance can use total_gpu_memory (14.74GiB) x gpu_memory_utilization (0.95) = 14.00GiB\nINFO 07-26 05:00:46 [worker.py:295] model weights take 9.16GiB; non_torch_memory takes 0.11GiB; PyTorch activation peak memory takes 2.95GiB; the rest of the memory reserved for KV Cache is 1.79GiB.\nINFO 07-26 05:00:47 [executor_base.py:113] # cuda blocks: 861, # CPU blocks: 1927\nINFO 07-26 05:00:47 [executor_base.py:118] Maximum concurrency for 4096 tokens per request: 3.36x\nINFO 07-26 05:00:51 [llm_engine.py:424] init engine (profile, create kv cache, warmup model) took 53.17 seconds\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from vllm import SamplingParams\n\nsampling_params = SamplingParams(\n    temperature=0.7,\n    top_p=0.9,\n    max_tokens=1000,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T05:15:41.941274Z","iopub.execute_input":"2025-07-26T05:15:41.941763Z","iopub.status.idle":"2025-07-26T05:15:41.945373Z","shell.execute_reply.started":"2025-07-26T05:15:41.941740Z","shell.execute_reply":"2025-07-26T05:15:41.944709Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"test_data = pd.read_csv('/kaggle/input/binary-biplob-can-you-decode-emotions/bangla/test.csv')\ntest_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T05:21:19.231525Z","iopub.execute_input":"2025-07-26T05:21:19.231822Z","iopub.status.idle":"2025-07-26T05:21:19.266942Z","shell.execute_reply.started":"2025-07-26T05:21:19.231801Z","shell.execute_reply":"2025-07-26T05:21:19.266288Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"           id                                text\n0  sample_798          I bought a নতুন বই to read\n1  sample_141  Bondhudero sathe ghurte giyechilam\n2  sample_675           Bazare aj onek bhir chilo\n3  sample_574  এই movie টা really interesting ছিল\n4  sample_488        সন্ধ্যায় পার্কে হাঁটতে যাবো","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sample_798</td>\n      <td>I bought a নতুন বই to read</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sample_141</td>\n      <td>Bondhudero sathe ghurte giyechilam</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sample_675</td>\n      <td>Bazare aj onek bhir chilo</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sample_574</td>\n      <td>এই movie টা really interesting ছিল</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>sample_488</td>\n      <td>সন্ধ্যায় পার্কে হাঁটতে যাবো</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"sentences = test_data['text'].tolist()\nsentences[:5]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T05:23:36.808733Z","iopub.execute_input":"2025-07-26T05:23:36.809512Z","iopub.status.idle":"2025-07-26T05:23:36.815705Z","shell.execute_reply.started":"2025-07-26T05:23:36.809490Z","shell.execute_reply":"2025-07-26T05:23:36.815180Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"['I bought a নতুন বই to read',\n 'Bondhudero sathe ghurte giyechilam',\n 'Bazare aj onek bhir chilo',\n 'এই movie টা really interesting ছিল',\n 'সন্ধ্যায় পার্কে হাঁটতে যাবো']"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"sys_prompt = '''You are a multilingual language model who understands Bengali, English, and Banglish (a mixture of Bengali and English).\nYour task is to analyze the sentiment of the below sentence and answer in sentiment category ('negative', 'positive', 'neutral').\nYou should think step by step and give me the answer in the box like {{positive}}.'''\n\n# Create full prompts by combining system prompt with sentence\nprompts = [f\"{sys_prompt}\\nSentence: {sentence}\" for sentence in sentences]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T05:24:00.663767Z","iopub.execute_input":"2025-07-26T05:24:00.664081Z","iopub.status.idle":"2025-07-26T05:24:00.668046Z","shell.execute_reply.started":"2025-07-26T05:24:00.664029Z","shell.execute_reply":"2025-07-26T05:24:00.667255Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"prompts[:2]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T05:24:32.241999Z","iopub.execute_input":"2025-07-26T05:24:32.242302Z","iopub.status.idle":"2025-07-26T05:24:32.246962Z","shell.execute_reply.started":"2025-07-26T05:24:32.242283Z","shell.execute_reply":"2025-07-26T05:24:32.246380Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"[\"You are a multilingual language model who understands Bengali, English, and Banglish (a mixture of Bengali and English).\\nYour task is to analyze the sentiment of the below sentence and answer in sentiment category ('negative', 'positive', 'neutral').\\nYou should think step by step and give me the answer in the box like {{positive}}.\\nSentence: I bought a নতুন বই to read\",\n \"You are a multilingual language model who understands Bengali, English, and Banglish (a mixture of Bengali and English).\\nYour task is to analyze the sentiment of the below sentence and answer in sentiment category ('negative', 'positive', 'neutral').\\nYou should think step by step and give me the answer in the box like {{positive}}.\\nSentence: Bondhudero sathe ghurte giyechilam\"]"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"from vllm import SamplingParams\n\nsampling_params = SamplingParams(\n    temperature=0.7,\n    top_p=0.9,\n    max_tokens=2000,\n)\n\n# Generate predictions\nresults = llm.generate(prompts, sampling_params)\n\n# Extract results\noutputs = [res.outputs[0].text.strip() for res in results]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T05:25:16.783418Z","iopub.execute_input":"2025-07-26T05:25:16.783702Z","iopub.status.idle":"2025-07-26T05:25:57.201634Z","shell.execute_reply.started":"2025-07-26T05:25:16.783683Z","shell.execute_reply":"2025-07-26T05:25:57.200774Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Adding requests:   0%|          | 0/120 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd2d1964c3de4c5dba1c209694424d4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Processed prompts:   0%|          | 0/120 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"543a34f7b2c44e4fb13bc7806d8fd35b"}},"metadata":{}},{"name":"stdout","text":"WARNING 07-26 05:25:33 [scheduler.py:1822] Sequence group 136 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"outputs[:5]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T05:25:57.202633Z","iopub.execute_input":"2025-07-26T05:25:57.202847Z","iopub.status.idle":"2025-07-26T05:25:57.207533Z","shell.execute_reply.started":"2025-07-26T05:25:57.202829Z","shell.execute_reply":"2025-07-26T05:25:57.206894Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"['.\\nStep 1: Analyze the words in the sentence. \"নতুন\" (new) is generally positive. \"বই\" (book) is an object, so it\\'s neutral. \"to read\" suggests an activity, which can be positive or neutral depending on the context.\\nStep 2: Considering the overall context, the sentence expresses a positive action - buying a new book to read.\\nStep 3: Therefore, the sentiment of the sentence is positive.\\n\\n{{',\n ', ami dukkhito hotoi.\\n\\nHere is how you should analyze the sentence:\\n1. Understand the meaning of the sentence.\\n2. Identify the words that express sentiment.\\n3. Determine the overall sentiment.\\n\\nSentence: Bondhudero sathe ghurte giyechilam, ami dukkhito hotoi.\\n1. The sentence means \"I went with friends, I am feeling sad.\"\\n2. The word \"dukkito\" (sad) expresses',\n '.\\nLet\\'s analyze the sentence.\\nThe sentence \"Bazare aj onek bhir chilo\" in Bengali translates to \"Today there are many shops in the market.\"\\nThe words \"onek bhir\" (many shops) generally have a positive connotation as they indicate abundance and activity.\\nThe sentence describes a positive situation - a market with many shops.\\nTherefore, the sentiment of the sentence is positive.\\n\\n{{positive}}',\n '।\\nStep 1: Analyze the sentence in Bengali.\\nThe sentence \"এই movie টা really interesting ছিল\" translates to \"This movie was really interesting.\"\\nStep 2: Identify the positive words.\\nThe word \"interesting\" is a positive adjective. \"really\" is an intensifier that strengthens the positive sentiment.\\nStep 3: Determine the overall sentiment.\\nThe sentence expresses a positive opinion about the movie.\\n{{positive}}',\n '।\\nTranslation: I am going to walk in the park in the evening.\\nAnalysis: The sentence expresses an activity (walking) that the speaker intends to do in a pleasant setting (park) during a time of day (evening). There is no indication of negative feelings or sadness. It sounds like a plan for a relaxing and enjoyable activity.\\n{{positive}}']"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"import re\ndef extract_sentiment(text):\n    match = re.search(r\"\\{\\{(positive|negative|neutral)\\}\\}\", text.lower())\n    return match.group(1) if match else \"unknown\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T05:34:50.764291Z","iopub.execute_input":"2025-07-26T05:34:50.764589Z","iopub.status.idle":"2025-07-26T05:34:50.768811Z","shell.execute_reply.started":"2025-07-26T05:34:50.764568Z","shell.execute_reply":"2025-07-26T05:34:50.768191Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"predicted = [extract_sentiment(res.outputs[0].text.strip()) for res in results]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T05:34:56.760128Z","iopub.execute_input":"2025-07-26T05:34:56.760630Z","iopub.status.idle":"2025-07-26T05:34:56.765315Z","shell.execute_reply.started":"2025-07-26T05:34:56.760608Z","shell.execute_reply":"2025-07-26T05:34:56.764557Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# Save to submission.csv format\nsubmission = pd.DataFrame({\n    \"id\": test_data[\"id\"],\n    \"label\": predicted\n})\nsubmission.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T05:35:41.027334Z","iopub.execute_input":"2025-07-26T05:35:41.027983Z","iopub.status.idle":"2025-07-26T05:35:41.036130Z","shell.execute_reply.started":"2025-07-26T05:35:41.027959Z","shell.execute_reply":"2025-07-26T05:35:41.035433Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"           id     label\n0  sample_798   unknown\n1  sample_141   unknown\n2  sample_675  positive\n3  sample_574  positive\n4  sample_488  positive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sample_798</td>\n      <td>unknown</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sample_141</td>\n      <td>unknown</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sample_675</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sample_574</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>sample_488</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T05:35:52.058620Z","iopub.execute_input":"2025-07-26T05:35:52.059303Z","iopub.status.idle":"2025-07-26T05:35:52.067616Z","shell.execute_reply.started":"2025-07-26T05:35:52.059279Z","shell.execute_reply":"2025-07-26T05:35:52.067076Z"}},"outputs":[],"execution_count":33}]}